<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: openstack | jamielennox.net]]></title>
  <link href="http://www.jamielennox.net/blog/categories/openstack/atom.xml" rel="self"/>
  <link href="http://www.jamielennox.net/"/>
  <updated>2014-08-15T14:24:44+10:00</updated>
  <id>http://www.jamielennox.net/</id>
  <author>
    <name><![CDATA[Jamie Lennox]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Git Commands for Messy People]]></title>
    <link href="http://www.jamielennox.net/blog/2014/08/15/git-commands-for-messy-people/"/>
    <updated>2014-08-15T10:59:00+10:00</updated>
    <id>http://www.jamielennox.net/blog/2014/08/15/git-commands-for-messy-people</id>
    <content type="html"><![CDATA[<p>I am terrible at keeping my git branches in order.
Particularly since I work across multiple machines and forget where things are I will often have multiple branches with different names being different versions of the same review.</p>

<p>On a project I work on frequently I currently have 71 local branches which are a mix of my code, some code reviews, and some branches that were for trialling ideas.
<a href="https://pypi.python.org/pypi/git-review">git review</a> at least prefixes branches it downloads with <code>review/</code> but that doesn&rsquo;t help to figure out what was happening with local branches labelled <code>auth</code> through <code>auth-4</code>.</p>

<p>However this post isn&rsquo;t about me fixing my terrible habit it&rsquo;s about two git commands which help me work with the mess.</p>

<p>The first is an alias which I called <code>branch-date</code>:</p>

<p><div class='bogus-wrapper'><notextile><figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='ini'><span class='line'><span class="k">[alias]</span>
</span><span class='line'>    <span class="na">branch-date</span> <span class="o">=</span> <span class="s">&amp;ldquo;!git for-each-ref &amp;ndash;sort=committerdate &amp;ndash;format=&amp;lsquo;%1B[32m%(committerdate:iso8601) %1B[34m%(committerdate:relative) %1B[0;m%(refname:short)&amp;rsquo; refs/heads/&amp;rdquo;</span>
</span></code></pre></td></tr></table></div></figure></notextile></div></p>

<p>This gives a nicely formatted list of branches in the project sorted by the last time they were committed to and how long ago it was.
So if I know I&rsquo;m looking for a branch that I last worked on last week I can quickly locate those branches.</p>

<p><img class="&ldquo;basic-alignment center&rdquo;" src="/images/branch-date.png" title="&ldquo;Naming scheme win!&rdquo; &ldquo;List of branches ordered by date&rdquo;" ></p>

<p>The next is a script to figure out which of my branches have made it through review and have been merged upstream which I called <code>branch-merged</code>.</p>

<p>Using git you can already call <code>git branch --merged master</code> to determine which branches are fully merged into the <code>master</code> branch.
However this won&rsquo;t take into account if a later version of a review was merged, in which case I can probably get rid of that branch.</p>

<p>We can figure this out by using the <code>Commit-Id:</code> field of our Gerrit reviews.</p>

<p><div><script src='https://gist.github.com/a7f8080e42ec795945b8.js?file=git-branch-merged.sh'></script>
<noscript><pre><code>#!/bin/bash

# create an associative array of all the changes
declare -A MERGED
for commit in `git log master | grep Change-Id | cut -d : -f 2`; do
    MERGED[&quot;$commit&quot;]=1
done

for branch in `git branch | grep -v master`; do
    found=1

    # for every commit on the branch check to ensure its in master
    for commit in `git log $branch | grep Change-Id | cut -d : -f 2`; do
        if [[ ! ${MERGED[&quot;$commit&quot;]} ]]; then
            # if it's not in master then this branch wasn't merged so we
            # want to break out and not print its name.
            found=0
            break
        fi
    done

    if [ $found = 1 ]; then
        # if all of the Commit-Ids on branch were also in master then
        # print out the branch name because we can probably get rid of it
        echo $branch
    fi
done</code></pre></noscript></div>
</p>

<p>So print out the branches where all the <code>Commit-Id</code>s are also in master.
It&rsquo;s not greatly efficient and if you are working with code bases with long histories you might need to limit the depth, but given that it doesn&rsquo;t run often it completes quickly enough.</p>

<p>There&rsquo;s no guarantee that there wasn&rsquo;t something new in those branches, but most likely it was an earlier review or test code that is no longer relevant.
I was considering a tool that could use the <code>Commit-Id</code> to figure out from gerrit if a branch is an exact match to one that was previously up for review and so contained no possibly useful experimenting code, but teaching myself to clean up branches as I go is probably a better use of my time.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[identity_uri in Auth Token Middleware]]></title>
    <link href="http://www.jamielennox.net/blog/2014/05/21/identity-uri-in-auth-token-middleware/"/>
    <updated>2014-05-21T14:54:00+10:00</updated>
    <id>http://www.jamielennox.net/blog/2014/05/21/identity-uri-in-auth-token-middleware</id>
    <content type="html"><![CDATA[<p>As part of the 0.8 release of keystoneclient (2014-04-17) we made an update to the way that you configure auth_token middleware in OpenStack.</p>

<p>Previously you specify the path to the keystone server as a number of individual parameters such as:</p>

<pre><code>[keystone_authtoken]
auth_protocol = http
auth_port = 35357
auth_host = 127.0.0.1
auth_admin_prefix =
</code></pre>

<p>This made sense in code when using httplib for communication where you use each of those independent pieces.
However we removed httplib a number of releases ago and now simply reconstruct the full URL in code in the form:</p>

<pre><code>%(auth_protocol)s://%(auth_host)s:%(auth_port)d/%(auth_admin_prefix)s
</code></pre>

<p>This format is much more intuitive for configuration and so should now be used with the key <strong>identity_uri</strong>. e.g.</p>

<pre><code>[keystone_authtoken]
identity_uri = http://127.0.0.1:35357
</code></pre>

<p>Using the original format will continue to work but you&rsquo;ll see a deprecation message like:</p>

<pre><code>WARNING keystoneclient.middleware.auth_token [-] Configuring admin URI using auth fragments. This is deprecated, use 'identity_uri' instead.
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Client Session Objects]]></title>
    <link href="http://www.jamielennox.net/blog/2014/02/24/client-session-objects/"/>
    <updated>2014-02-24T13:32:00+10:00</updated>
    <id>http://www.jamielennox.net/blog/2014/02/24/client-session-objects</id>
    <content type="html"><![CDATA[<p>Keystoneclient has recently introduced a <em>Session</em> object.
The concept was discussed and generally accepted at the Hong Kong Summit that keystoneclient as the root of authentication (and arguably security) should be responsible for transport (HTTP) and authentication across all the clients.</p>

<p>The majority of the functionality in this post is written and up for review but has <strong>not yet been committed</strong>.
I write this in an attempt to show the direction of clients as there is currently a lot of talk around projects such as the <a href="https://wiki.openstack.org/wiki/SDK-Development">OpenStack-SDK</a>.</p>

<p>When working with clients you would first create an authentication object, then create a session object with that authentication and then re-use that session object across all the clients you instantiate.</p>

<pre><code class="python">
from keystoneclient.auth.identity import v2
from keystoneclient import session
from keystoneclient.v2_0 import client

auth = v2.Password(auth_url='https://localhost:5000/v2.0',
                   username='user',
                   password='pass',
                   tenant_name='demo')

sess = session.Session(auth=auth,
                       verify='/path/to/ca.pem')

ksclient = client.Client(session=sess,
                         region_name='RegionOne')
# other clients can be created sharing the sess parameter
</code></pre>

<p>Now whenever you want to make an authenticated request you just indicated it as part of the request call.</p>

<pre><code class="python">
# requests with authenticated are sent with a token
users = sess.get('http://localhost:35357/v2.0/users',
                 authenticated=True)
</code></pre>

<p>This was pretty much the extent of the initial proposal, however in working with the plugins I have come to realize that authentication is responsible for much more than simply getting a token.</p>

<p>A large part of the data in a keystone token is the service catalog.
This is a listing of the services known to an OpenStack deployment and the URLs that we should use when accessing those services.
Because of the disjointed way in which clients have been developed this service catalog is parsed by each client to determine the URL with which to make API calls.</p>

<p>With a session object in control of authentication and the service catalog there is no reason for a client to know its URL, just what it wants to communicate.</p>

<pre><code class="python">
users = sess.get('/users',
                 authenticated=True,
                 service_type='identity',
                 endpoint_type='admin',
                 region_name='RegionOne')
</code></pre>

<p>The values of <code>service_type</code> and <code>endpoint_type</code> are well known and constant to a client, <code>region_name</code> is generally passed in when instantiating (if required).
Requests made via the client object will have these parameters added automatically, so given the client from above the following call is exactly the same:</p>

<pre><code class="python">
users = ksclient.get('/users')
</code></pre>

<p>Where I feel that this will really begin to help though is in dealing with the transition between API versions.</p>

<p>Currently deployments of OpenStack put a versioned endpoint in the service catalog eg for identity <code>http://localhost:5000/v2.0</code>.
This made sense initially however now as we try to transition people to the V3 identity API we find that there is no backwards compatible way to advertise both the v2 and v3 services.
The agreed solution long-term is that entries in the service catalog should not be versioned eg. <code>http://localhost:5000</code> as the root path of a service will list the available versions.
So how do we handle this transition across the 8+ clients?
Easy:</p>

<pre><code class="python">
try:
    users = sess.get('/users',
                     authenticated=True,
                     service_type='identity',
                     endpoint_type='admin',
                     region_name='RegionOne',
                     version=(2, 0))  # just specify the version you need
except keystoneclient.exceptions.EndpointNotFound:
    logging.error('No v2 identity endpoint available', exc_info=True)
</code></pre>

<p>This solution also means that when we have a suitable hack for the transition to unversioned endpoints it needs only be implemented in one place.</p>

<p>Reliant on this is a means to discover the available versions of all the OpenStack services.
Turns out that in general the projects are similar enough in structure that it can be done with a few minor hacks.
For newer projects there is now a definitive specification <a href="https://wiki.openstack.org/wiki/VersionDiscovery">on the wiki</a>.</p>

<p>A major advantage of this common approach is we now have a standard way of determining whether a version of a project is available in this cloud.
Therefore we get client version discovery pretty much for free:</p>

<pre><code class="python">
if sess.is_available(service_type='identity',
                     version=(2,0)):
    ksclient = v2_0.client.Client(sess)
else:
    logging.error("Can't create a v2 identity client")
</code></pre>

<p>That&rsquo;s a little verbose as a client knows that information, so we can extract a wrapper:</p>

<pre><code class="python">
if v2_0.client.Client.is_available(sess):
    ksclient = v2_0.client.Client(sess)
</code></pre>

<p>or simply:</p>

<pre><code class="python">
ksclient = keystoneclient.client.Client(session=sess,
                                        version=(2,0))
if ksclient:
    # do stuff
</code></pre>

<p>So the session object has evolved from a pure transport level object and this departure is somewhat concerning as I don&rsquo;t like mixing layers of responsibility.
However in practice we have standardized on the <a href="http://www.python-requests.org">requests</a> library to abstract much of this away and the Session object is providing helpers around this.</p>

<p>So, along with standardizing transport, by using the session object like this we can:</p>

<ul>
<li>reduce the basic client down to an object consisting of a few variables indicating the service type and version required.</li>
<li>finally get a common service discovery mechanism for all the clients.</li>
<li>shift the problem of API version migration onto someone else - probably me.</li>
</ul>


<h4>Disclaimers and Notes</h4>

<ul>
<li><p>The examples provided above use keystoneclient and the &lsquo;identity&rsquo; service purely because this is what has been implemented so far.
In terms of CRUD operations keystoneclient is essentially the same as other client in that it retrieves its endpoint from the service catalog and issues requests to it, so the approach will work equally well.</p></li>
<li><p>Currently none of the other clients rely upon the session object, I have been waiting on the inclusion of authentication plugins and service discovery before making this push.</p></li>
<li><p>Region handling is still a little awkward when using the clients.
I blame this completely on the fact that region handling is awkward on the servers.
In Juno we should have hierarchical regions and then it may make sense to allow <code>region_name</code> to be set on a session rather than per client.</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dealing with .pyc]]></title>
    <link href="http://www.jamielennox.net/blog/2014/02/18/dealing-with-pyc/"/>
    <updated>2014-02-18T11:08:00+10:00</updated>
    <id>http://www.jamielennox.net/blog/2014/02/18/dealing-with-pyc</id>
    <content type="html"><![CDATA[<p>I have often found that when dealing with multiple branches and refactoring patches I get caught out by left over *.pyc files from python files that don&rsquo;t exist on this branch.
This bit me again recently so I went looking for options.</p>

<p>A useful environment variable that I found via some stackoverflow questions is: <a href="http://docs.python.org/2/using/cmdline.html#envvar-PYTHONDONTWRITEBYTECODE">PYTHONDONTWRITEBYTECODE</a> which, when set, prevents python from writing .pyc and .pyo files.
This is not something that I want to set permanently on my machine but is great for development.</p>

<p>The other tool I use for all my python projects is <a href="http://virtualenvwrapper.readthedocs.org/en/latest/">virtualenvwrapper</a> which allows you to isolate project dependencies and environments in what I think is a more intuitive way than with virtualenv directly.</p>

<p>Armed with the simple idea that these two concepts should be able to work together I found I was not the first person to think of this.
There are other guides out there but the basic concept is simply to set PYTHONDONTWRITEBYTECODE when we activate a virtualenv and reset it when we deactivate it.</p>

<p>Easy.</p>

<p>Add to <em>~/.virtualenvs/postactivate</em>:</p>

<pre><code class="bash">export _PYTHONDONTWRITEBYTECODE=$PYTHONDONTWRITEBYTECODE
export PYTHONDONTWRITEBYTECODE=1
</code></pre>

<p>Add to <em>~/.virtualenvs/predeactivate</em>:</p>

<pre><code class="bash">export PYTHONDONTWRITEBYTECODE=$_PYTHONDONTWRITEBYTECODE
unset _PYTHONDONTWRITEBYETCODE
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Keystone Token Binding]]></title>
    <link href="http://www.jamielennox.net/blog/2013/10/22/keystone-token-binding/"/>
    <updated>2013-10-22T11:48:00+10:00</updated>
    <id>http://www.jamielennox.net/blog/2013/10/22/keystone-token-binding</id>
    <content type="html"><![CDATA[<p>With the Havana release of OpenStack, Keystone gains the ability to issue and verify tokens &ldquo;bound&rdquo; to some authentication mechanism.
To understand the reason for this feature we need to first consider the security model of the current token architecture.</p>

<p>OpenStack tokens are what we call &ldquo;bearer tokens&rdquo;.
The term seems to have come out of the OAuth movement but means that whoever has the token has all the rights associated with that person.
This is not an uncommon situation on the Internet, it is the way basic auth (username and password), cookies, and session ids all work, and one of the reasons that SSL is so important when authenticating against a website.
If an attacker was to get your token then they have all the rights of that token for as long as it is valid, including permission to reissue a token or change your password.
While all of these mechanism are symmetric secrets, they are only shared between two end points.
Keystone tokens are shared across all of the public services in an OpensStack deployment.</p>

<p>As OpenStack grows and this token is presented to an ever increasing list of services the vulnerability of this mechanism increases.
So what can we do about it?
The typical answer, particularly for the enterprise, is to use Kerberos or x509 client certificates.
This is a great solution but we don&rsquo;t want to have each service dealing with different authentication mechanisms, that&rsquo;s what Keystone does.</p>

<h2>What is a &ldquo;bound token&rdquo;?</h2>

<p>A &ldquo;bound token&rdquo; is a regular keystone token with some additional information that indicates that the token may only be used in conjunction with the specified external authentication mechanism.
Taking the example of Kerberos, when a token is issued Keystone embeds the name of the Kerberos principle into the token.
When this token is then presented to another service the service notices the bind information and ensures that Kerberos authentication was used and that the same user is making the request.</p>

<p>So how does this help to protect token hijacking?
To give an example:</p>

<ol>
<li> Alice connects to Keystone using her Kerberos credentials and gets a token.
 Embedded within this token is her Kerberos principal name <code>alice@ACME.COM</code>.</li>
<li> Alice authenticates to HaaS (hacked as a service) using her token and Kerberos credentials and is allowed to perform her operations.</li>
<li> Bob, who has privileged access to HaaS, records the token that Alice presented to the service (or otherwise gets Alice&rsquo;s token)</li>
<li> Bob attempts to connect to Keystone as Alice to change her password.
 He connects to keystone with his own Kerberos credentials <code>bob@ACME.COM</code>.
 Because these credentials do not match the ones that were present when the token was created his access is disallowed.</li>
</ol>


<p>It does not necessarily mean that the user initially authenticated themselves by there Kerberos credentials, they may have used there regular username and password.
It simply means that the user who created the token has said that they are also the owner of this Kerberos principal (note: that it is tied to the principal, not a ticket so it will survive ticket re-issuing) and the token should not be authenticated in future without it present.</p>

<h2>What is implemented?</h2>

<p>Currently tokens issued from Keystone can be bound to a Kerberos principal.
Extending this mechanism to x509 client certificates should be a fairly simple exercise but will not be included in the Havana release.</p>

<p>A patch to handle bind checking in auth_token middleware is currently under review to bring checking to other services.</p>

<p>There are however a number of problems with enforcing bound tokens today:</p>

<ul>
<li>Kerberos authentication is not supported by the eventlet http server (the server that drives most of the OpenStack web services), and so there is no way to authenticate to the server to provide the credentials.
This essentially restricts bind checking to services running in httpd, which to the best of my knowledge is currently only keystone and swift.</li>
<li>None of the clients currently support connecting with Kerberos authentication.
The option was added to Keystoneclient as a proof of concept but I am hoping that this can be solved across all clients by standardizing the way they communicate rather than having to add and maintain support in each individual client.
There will also be the issue of how to configure the servers to use these clients correctly.</li>
<li>Kerberos tickets are issued to users, not hosts, and typically expire after a period of time.
To allow unattended servers to have valid Kerberos credentials requires a way of automatically refreshing or fetching new tickets.
I am told that there is support for this scenario coming in Fedora 20 but I am not sure what it will involve.</li>
</ul>


<h2>Configuring Token Binding</h2>

<p>The new argument to enable token binding in <code>keystone.conf</code> is:</p>

<pre><code>[token]

# External auth mechanisms that should add bind information to token.
# eg kerberos, x509
bind = kerberos
</code></pre>

<p>As mentioned currently only the value Kerberos is currently supported here.
One of the next supported mechanisms will be x509 client certificates.</p>

<p>To enable token bind authentication in <code>keystone.conf</code> is:</p>

<pre><code>[token]
# Enforcement policy on tokens presented to keystone with bind information.
# One of disabled, permissive, strict, required or a specifically required bind
# mode e.g. kerberos or x509 to require binding to that authentication.
enforce_token_bind = permissive
</code></pre>

<p>As illustrated by the comments the possible values here are:</p>

<ul>
<li><code>disabled</code>: Disables token bind checking.</li>
<li><code>permissive</code>: Token bind information will be verified if present.
 If there is bind information for a token and the server does not know how to verify that information then it will be ignored and the token will be allowed.
 This is the new default value and should have no effect on existing systems.</li>
<li><code>strict</code>: Like permissive but if unknown bind information is present then the token will be rejected.</li>
<li><code>required</code>: Tokens will only be allowed if bind information is present and verified.</li>
<li>A specific form of bind information is present and verified.
The only currently available value here is <code>kerberos</code> indicating that a token must be bound to a Kerberos principal to be accepted.</li>
</ul>


<h2>In Conclusion</h2>

<p>For a deployment with access to a Kerberos or x509 infrastructure token binding will dramatically increase your user&rsquo;s security.
Unfortunately the limitations of Kerberos within OpenStack don&rsquo;t really make this a viable deployment option in Havana.
Watch this space however as we add x509 authentication and binding, and improve Kerberos handling throughout.</p>
]]></content>
  </entry>
  
</feed>
